{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a0ffc09-5c13-48b4-94fb-2b03e49588a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import glob\n",
    "import get_Amaps as amap\n",
    "import get_BCDEmaps as bcde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6060c796-7617-4614-ad00-a6f1885cff30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get file path glob containing all years 1850-2014\n",
    "filepath = \"../NINT_ensemble/ij_concat_files/1850-1900_prec_E213f10*F40oQ40_3.nc\"\n",
    "model_id = \"1\" # id character or phrase for model\n",
    "\n",
    "# Make dataset from files, sometimes one file sometimes multiple. Use mfdataset if glob\n",
    "# ds = xr.open_mfdataset(fileglob) # if combining multiple files into one dataset\n",
    "ds = xr.open_mfdataset(filepath, combine=\"nested\", concat_dim=\"ensemble_member\")\n",
    "# Sort ds by time\n",
    "ds = ds.sortby(\"time\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5387eb38-8809-4954-a75b-a19b7510889a",
   "metadata": {},
   "source": [
    "## preindustrial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f7abd998-ff55-4e49-b1e1-d037d703484e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: FutureWarning: 'Y' is deprecated and will be removed in a future version. Please use 'YE' instead of 'Y'.\n",
      "<string>:6: FutureWarning: 'Y' is deprecated and will be removed in a future version. Please use 'YE' instead of 'Y'.\n"
     ]
    }
   ],
   "source": [
    "# time pd and variable\n",
    "timepd = \"preindustrial\"\n",
    "var = \"prec\"\n",
    "\n",
    "# r1mm\n",
    "var_out = \"r1mm\"\n",
    "file_name_out = f\"{var_out}_ensavg\" # out file name ( _{timeperiod}_{letter}.nc will be concatenated)\n",
    "amap.get_A_maps(ds, var_out, var, filepath, file_name_out, timepd, 5, model_id) # outputs will be saved to current dir\n",
    "\n",
    "# r10mm\n",
    "var_out = \"r10mm\"\n",
    "file_name_out = f\"{var_out}_ensavg\" # out file name ( _{timeperiod}_{letter}.nc will be concatenated)\n",
    "amap.get_A_maps(ds, var_out, var, filepath, file_name_out, timepd, 5, model_id) # outputs will be saved to current dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e1f4a922-1443-41b5-99a7-a6b29b90b5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mypcpls/anaconda3/envs/geo/lib/python3.12/site-packages/xarray/core/indexing.py:1621: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/home/mypcpls/anaconda3/envs/geo/lib/python3.12/site-packages/xarray/core/indexing.py:1621: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "<string>:6: FutureWarning: 'Y' is deprecated and will be removed in a future version. Please use 'YE' instead of 'Y'.\n",
      "/home/mypcpls/anaconda3/envs/geo/lib/python3.12/site-packages/xarray/core/indexing.py:1621: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/home/mypcpls/anaconda3/envs/geo/lib/python3.12/site-packages/xarray/core/indexing.py:1621: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "<string>:6: FutureWarning: 'Y' is deprecated and will be removed in a future version. Please use 'YE' instead of 'Y'.\n"
     ]
    }
   ],
   "source": [
    "# t40c\n",
    "# Get file path glob containing all years 1850-2014\n",
    "filepath = \"../NINT_ensemble/ij_concat_files/1850-1900_tsmax_E213f10*F40oQ40_3.nc\"\n",
    "ds = xr.open_mfdataset(filepath, combine=\"nested\", concat_dim=\"ensemble_member\")\n",
    "ds = ds.sortby(\"time\") \n",
    "\n",
    "var = \"tsmax\"\n",
    "var_out = \"t40C\"\n",
    "file_name_out = f\"{var_out}_ensavg\" # out file name ( _{timeperiod}_{letter}.nc will be concatenated)\n",
    "amap.get_A_maps(ds, var_out, var, filepath, file_name_out, timepd, 5, model_id) # outputs will be saved to current dir\n",
    "\n",
    "# r10mm\n",
    "# Get file path glob containing all years 1850-2014\n",
    "filepath = \"../NINT_ensemble/ij_concat_files/1850-1900_tsmin_E213f10*F40oQ40_3.nc\"\n",
    "ds = xr.open_mfdataset(filepath, combine=\"nested\", concat_dim=\"ensemble_member\")\n",
    "ds = ds.sortby(\"time\") \n",
    "\n",
    "var = \"tsmin\"\n",
    "var_out = \"fd\"\n",
    "file_name_out = f\"{var_out}_ensavg\" # out file name ( _{timeperiod}_{letter}.nc will be concatenated)\n",
    "amap.get_A_maps(ds, var_out, var, filepath, file_name_out, timepd, 5, model_id) # outputs will be saved to current dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f563bf-412e-460a-8d11-e64ae0447822",
   "metadata": {},
   "source": [
    "## modern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d5d72257",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: FutureWarning: 'Y' is deprecated and will be removed in a future version. Please use 'YE' instead of 'Y'.\n",
      "<string>:6: FutureWarning: 'Y' is deprecated and will be removed in a future version. Please use 'YE' instead of 'Y'.\n"
     ]
    }
   ],
   "source": [
    "# time pd and variable\n",
    "timepd = \"modern\"\n",
    "var = \"prec\"\n",
    "\n",
    "# Get file path glob containing all years 1850-2014\n",
    "filepath = \"../NINT_ensemble/ij_concat_files/1980-2014_prec_E213f10*F40oQ40_3.nc\"\n",
    "ds = xr.open_mfdataset(filepath, combine=\"nested\", concat_dim=\"ensemble_member\")\n",
    "ds = ds.sortby(\"time\") \n",
    "\n",
    "# r1mm\n",
    "var_out = \"r1mm\"\n",
    "file_name_out = f\"{var_out}_ensavg\" # out file name ( _{timeperiod}_{letter}.nc will be concatenated)\n",
    "amap.get_A_maps(ds, var_out, var, filepath, file_name_out, timepd, 5, model_id) # outputs will be saved to current dir\n",
    "\n",
    "# r10mm\n",
    "var_out = \"r10mm\"\n",
    "file_name_out = f\"{var_out}_ensavg\" # out file name ( _{timeperiod}_{letter}.nc will be concatenated)\n",
    "amap.get_A_maps(ds, var_out, var, filepath, file_name_out, timepd, 5, model_id) # outputs will be saved to current dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5f293fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: FutureWarning: 'Y' is deprecated and will be removed in a future version. Please use 'YE' instead of 'Y'.\n",
      "<string>:6: FutureWarning: 'Y' is deprecated and will be removed in a future version. Please use 'YE' instead of 'Y'.\n"
     ]
    }
   ],
   "source": [
    "# t40c\n",
    "# Get file path glob containing all years 1850-2014\n",
    "filepath = \"../NINT_ensemble/ij_concat_files/1980-2014_tsmax_E213f10*F40oQ40_3.nc\"\n",
    "ds = xr.open_mfdataset(filepath, combine=\"nested\", concat_dim=\"ensemble_member\")\n",
    "ds = ds.sortby(\"time\") \n",
    "\n",
    "var = \"tsmax\"\n",
    "var_out = \"t40C\"\n",
    "file_name_out = f\"{var_out}_ensavg\" # out file name ( _{timeperiod}_{letter}.nc will be concatenated)\n",
    "amap.get_A_maps(ds, var_out, var, filepath, file_name_out, timepd, 5, model_id) # outputs will be saved to current dir\n",
    "\n",
    "# r10mm\n",
    "# Get file path glob containing all years 1850-2014\n",
    "filepath = \"../NINT_ensemble/ij_concat_files/1980-2014_tsmin_E213f10*F40oQ40_3.nc\"\n",
    "ds = xr.open_mfdataset(filepath, combine=\"nested\", concat_dim=\"ensemble_member\")\n",
    "ds = ds.sortby(\"time\") \n",
    "\n",
    "var = \"tsmin\"\n",
    "var_out = \"fd\"\n",
    "file_name_out = f\"{var_out}_ensavg\" # out file name ( _{timeperiod}_{letter}.nc will be concatenated)\n",
    "amap.get_A_maps(ds, var_out, var, filepath, file_name_out, timepd, 5, model_id) # outputs will be saved to current dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "87317a95-ad57-4f6d-b145-8ff5cc77c49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "need model E3 regridded A\n"
     ]
    }
   ],
   "source": [
    "# Produce B maps\n",
    "for cid in [\"R10mm\", \"R1mm\", \"T40C\", \"fd\"]:\n",
    "    cid_lower = \"t40C\" if cid == \"T40C\" else cid.lower()\n",
    "    if (cid == \"R10mm\") | (cid == \"R1mm\"):\n",
    "        folder = \"WetAndDry\"\n",
    "    else:\n",
    "        folder = \"HeatAndCold\"\n",
    "    for mid in [2, 3, 4, 5, 6, 7, 8,]: #10]:\n",
    "        dsA = xr.open_dataset(f\"data4maps/{folder}/{cid}/{cid_lower}_{mid}A.nc\")\n",
    "        defaultA = xr.open_dataset(f\"processed_ens/{cid_lower}_ensavg_modern_1A.nc\")\n",
    "        B = bcde.bcde_map(dsA, defaultA)\n",
    "        B.to_netcdf(f\"maps_vs_ens/{cid_lower}_{mid}B.nc\")\n",
    "print(\"need model E3 regridded A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5ae7775c-cdc5-4902-ac21-09413099105d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get D maps for default\n",
    "for cid in [\"R10mm\", \"R1mm\", \"T40C\", \"fd\"]:\n",
    "    cid_lower = \"t40C\" if cid == \"T40C\" else cid.lower()\n",
    "    if (cid == \"R10mm\") | (cid == \"R1mm\"):\n",
    "        folder = \"WetAndDry\"\n",
    "    else:\n",
    "        folder = \"HeatAndCold\"\n",
    "    defaultA = xr.open_dataset(f\"processed_ens/{cid_lower}_ensavg_modern_1A.nc\")\n",
    "    defaultA_pi = xr.open_dataset(f\"processed_ens/{cid_lower}_ensavg_preindustrial_1A.nc\")\n",
    "    defaultD = defaultA - defaultA_pi\n",
    "    defaultD.to_netcdf(f\"processed_ens/{cid_lower}_1D.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3dc86dcc-c221-4d70-93ab-06701b1dcadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "need model E3 regridded A\n"
     ]
    }
   ],
   "source": [
    "# Produce E maps\n",
    "for cid in [\"R10mm\", \"R1mm\", \"T40C\", \"fd\"]:\n",
    "    cid_lower = \"t40C\" if cid == \"T40C\" else cid.lower()\n",
    "    if (cid == \"R10mm\") | (cid == \"R1mm\"):\n",
    "        folder = \"WetAndDry\"\n",
    "    else:\n",
    "        folder = \"HeatAndCold\"\n",
    "    for mid in [2, 3, 4, 5, 6, 8,]: #10]:\n",
    "        dsD = xr.open_dataset(f\"data4maps/{folder}/{cid}/{cid_lower}_{mid}D.nc\")\n",
    "        defaultA = xr.open_dataset(f\"processed_ens/{cid_lower}_ensavg_modern_1A.nc\")\n",
    "        defaultA_pi = xr.open_dataset(f\"processed_ens/{cid_lower}_ensavg_preindustrial_1A.nc\")\n",
    "        defaultD = defaultA - defaultA_pi\n",
    "        B = bcde.bcde_map(dsD, defaultD)\n",
    "        B.to_netcdf(f\"maps_vs_ens/{cid_lower}_{mid}E.nc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
